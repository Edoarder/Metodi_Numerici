{
  
    
        "post0": {
            "title": "Modulo 1",
            "content": "%matplotlib inline import matplotlib.pyplot as plt import numpy as np . def initialstate(L,random=True,cold=+1): if random: state = 2*np.random.randint(2, size=L)-1 elif cold==1: state = np.int_(np.ones(L)) elif cold==-1: state = -np.int_(np.ones(L)) else: return print(&quot;Put cold = +1 or -1&quot;) return state . def mcmove(config, beta,A): &#39;&#39;&#39;Monte Carlo move using Metropolis algorithm &#39;&#39;&#39; con=config.copy() N=con.size for i in range(N): a = np.random.randint(0, N) s = con[a] cost=sum(-s*A[a,:]*con)-sum(s*A[a,:]*con) if -cost &lt; 0: s = -s elif np.random.rand() &lt; np.exp(cost*beta): s = -s con[a] = s return con . def calcEnergy(config): &#39;&#39;&#39;Energy of a given configuration&#39;&#39;&#39; energy = 0 for i in range(len(config)): S = config[i] energy += sum(-S*A[i]*config) return energy/config.size/4 def calcMag(config): &#39;&#39;&#39;Magnetization of a given configuration&#39;&#39;&#39; mag = np.sum(config) return mag/N . ## Matrice di adiacenza per Ising 2D di lato L L=4 N=L**2 A=np.zeros((N,N)) for i in range(N): A[i,(i+1)%N] =-1 A[i,(i-1)%N] =-1 A[i,(i+L)%N] =-1 A[i,(i-L)%N] =-1 #A=np.int_(A) import networkx as nx #N=10 B=nx.adjacency_matrix(nx.watts_strogatz_graph(N, 2, .1)) #A=A-(np.eye(N)*B) B . &lt;16x16 sparse matrix of type &#39;&lt;class &#39;numpy.int64&#39;&gt;&#39; with 32 stored elements in Compressed Sparse Row format&gt; . A=-np.ones((N,N)) . meas=20 dec=10 tn=20 ma=np.zeros(tn) en=np.zeros(tn) xi=np.zeros(tn) cs=np.zeros(tn) ma2=np.zeros(tn) en2=np.zeros(tn) m2=np.zeros(meas) e2=np.zeros(meas) mm=0 ee=0 for t in np.arange(tn): state=np.ones((meas,N)) state[0]=initialstate(N,random=False,cold=+1) #state[0,:]=np.ones(N) e=np.zeros(meas) m=np.zeros(meas) m[0]=calcMag(state[0]) for i in range(meas-1): # misure for j in range(dec): # decorrelazione #print(str(i)+&quot;: &quot;+str(state)) state[i+1,:]=mcmove(state[i,:], t/(tn/5), B).copy() m[i+1]=calcMag(state[i+1,:]) e[i+1]=calcEnergy(state[i+1,:]) m2[i+1]=m[i+1]*m[i+1] e2[i+1]=e[i+1]*e[i+1] m=m[meas//10:] ma[t]=sum(m)/meas ma2[t]=sum(m2)/meas en[t]=sum(e)/meas en2[t]=sum(e2)/meas xi[t]=ma2[t]-ma[t-1]**2 cs[t]=en2[t]-en[t-1]**2 tempe=np.arange(tn)/(tn/5)+1 plt.figure() plt.subplot(221) plt.scatter(tempe,abs(ma)) plt.xlabel(&#39;beta (1/T)&#39;) plt.ylabel(&#39;Magnetization&#39;) plt.subplot(222) plt.scatter(tempe,en) plt.xlabel(&#39;beta (1/T)&#39;) plt.ylabel(&#39;Energy&#39;) plt.subplot(223) plt.scatter(tempe,(xi)) plt.xlabel(&#39;beta (1/T)&#39;) plt.ylabel(&#39;Susceptibility&#39;) plt.subplot(224) plt.scatter(tempe,(cs)) plt.xlabel(&#39;beta (1/T)&#39;) plt.ylabel(&#39;Specific heat capacity&#39;) plt.show() .",
            "url": "https://edoarder.github.io/Metodi_Numerici/2020/06/08/Pising.html",
            "relUrl": "/2020/06/08/Pising.html",
            "date": " ‚Ä¢ Jun 8, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Modulo 2",
            "content": "Iniziamo con l&#39;implementazione dell&#39;algoritmo che diagonalizza l&#39;Hamiltoniana di un modello di Ising quantistico 1D con interazioni a primi vicini. . L&#39;implementazione consiste in alcuni step: . Si costruisce la base con cui rappresenter√≤ l&#39;Hamiltoniana . | Si costruisce l&#39;Hamiltoniana . | Si trova l&#39;autovalore minore e l&#39;autovettore corrispondente (Ground State) . | Si calcola la magnetizzazione associata al Ground State . | Si calcola la suscettivit√† magnetica e il calore specifico . | %matplotlib inline import matplotlib.pyplot as plt import numpy as np import scipy.sparse.linalg as ss from scipy.sparse import lil_matrix hh=0 volte=100 volte+=1 lins=np.linspace(0,2,volte) linell=np.arange(6,10) nell=linell.size magniz=np.zeros((volte,nell)) Egs=np.zeros((volte+1,nell)) xi=np.zeros((volte+1,nell)) ci=np.zeros((volte+1,nell)) ell1=0 for ell in linell: ggg=0 NumTot=2**ell ev=np.zeros((volte,NumTot)) Psii=np.zeros((volte,NumTot)) for gg in lins: PBC=True # Costruisco la base iSpin=np.zeros((NumTot,ell)) for ii in range(NumTot): itemp=ii for jj in range(ell): iSpin[ii,jj]=np.floor(itemp%2) itemp=itemp/2 # Costruisco l&#39;Hamiltoniana HamOut=lil_matrix(np.zeros((NumTot,NumTot))) # Sigma_z Sigma_z [coupling] for iHam in range(ell-1): for ii in range(NumTot): if iSpin[ii,iHam]==iSpin[ii,iHam+1]: HamOut[ii,ii]=HamOut[ii,ii]-1 else: HamOut[ii,ii]=HamOut[ii,ii]+1 # This implements periodic boundary conditions if PBC: for ii in range(NumTot): if iSpin[ii,ell-1]==iSpin[ii,0]: HamOut[ii,ii]=HamOut[ii,ii]-1 else: HamOut[ii,ii]=HamOut[ii,ii]+1 # Sigma_z [longitudinal field] for iHam in range(ell): for ii in range(NumTot): if iSpin[ii,iHam]==1: HamOut[ii,ii]=HamOut[ii,ii]-hh else: HamOut[ii,ii]=HamOut[ii,ii]+hh # Sigma_x [transverse field] contorta ma torna: in pratica cambia lo spin al sito j for iHam in range(ell): for ii in range(NumTot): if iSpin[ii,iHam]==1: Exc = ii - 2**(iHam) else: Exc = ii + 2**(iHam) HamOut[int(Exc),ii] = HamOut[int(Exc),ii] + gg # Trovo l&#39;autostato del GS Egs[ggg,ell1]=ss.eigsh(HamOut,1,which=&#39;SA&#39;)[0] Psi=ss.eigsh(HamOut,1,which=&#39;SA&#39;)[1].T[0] Psii[ggg]=Psi.copy() # Calcolo la magnetizzazione MagX=np.zeros(ell) MagZ=np.zeros(ell) MagnetZ=0 for iSite in range(ell): Mx_sum=0 for ii in range(NumTot): if iSpin[ii,iSite] == 1: MagZ[iSite] = MagZ[iSite] + abs(Psi[ii])**2 Exc = ii -2**(iSite) else: MagZ[iSite] = MagZ[iSite] - abs(Psi[ii])**2 Exc = ii +2**(iSite) Mx_sum = Mx_sum + np.conjugate(Psi[ii]) * Psi[Exc] if abs(np.imag(Mx_sum))&gt;10**(-10): print(&quot;Non real magnetization&quot;) MagX[iSite] = np.real(Mx_sum) for ii in range(NumTot): Mag_ii = 0 for iSite in range(ell): if iSpin[ii,iSite] == 1: Mag_ii = Mag_ii + 1 else: Mag_ii = Mag_ii - 1 MagnetZ = MagnetZ + abs(Mag_ii)*(abs(Psi[ii])**2) magniz[ggg,ell1]=MagnetZ/ell xi[ggg,ell1]=-(magniz[ggg-1,ell1]-magniz[ggg,ell1])/(lins[ggg-1]-lins[ggg]) ci[ggg,ell1]=-(Egs[ggg-1,ell1]-Egs[ggg,ell1])/(lins[ggg-1]-lins[ggg]) ggg+=1 ell1+=1 magniz1=magniz Egs1=Egs xi1=xi ci1=ci plt.figure(figsize=(12, 9)) plt.subplot(221) plt.plot(lins[1:],magniz[1:]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Magnetization&#39;) plt.subplot(222) plt.plot(lins[1:],Egs[1:volte]) #plt.ylim(-1,1) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Energy&#39;) plt.subplot(223) plt.plot(lins[1:],xi[1:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Susceptibility&#39;) plt.subplot(224) plt.plot(lins[1:],ci[1:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Specific heat capacity&#39;) plt.show() . Come possiamo notare la suscettivit√† magnetica presenta un picco in corrispondenza di $g=1$ che all&#39;aumentare della taglia del sistema diventa sempre pi√π accentuato, ad indicare che nel limite termodinamico si osserva un punto critico ed il sistema presenta una transizione da una fase ferromagnetica ad una paramagnetica all&#39;aumentare di $g$. . Per studiare meglio questo effetto procediamo con uno studio Finite Size Scaling. . Fmagniz=np.zeros((volte,nell)) Fxi=np.zeros((volte+1,nell)) Flins=np.zeros((volte,nell)) ell1=0 for ell in linell: Fmagniz[:,ell1]=magniz[:,ell1]*(ell)**(1/8) Fxi[:,ell1]=(xi[:,ell1]/(ell))**(7/4) Flins[:,ell1]=(lins-1)*(ell) ell1+=1 plt.figure(figsize=(12,5)) plt.subplot(121) plt.plot(Flins[1:],Fmagniz[1:]) plt.xlabel(&#39;(g-gùñº) L&#39;) plt.ylabel(&#39;|Mz| L·µù&#39;) plt.subplot(122) plt.plot(Flins[1:],Fxi[1:volte]) plt.xlabel(&#39;(g-gùñº) L&#39;) plt.ylabel(&#39;œá L·µû&#39;) plt.show() . Il Finite Size Scaling √® stato operato inserendo come esponenti critici quelli conosciuti tramite la risoluzione analitica del problema ovvero: $$ beta=1/8, quad gamma=7/4, quad nu=1, quad Y_g=1$$ . avendo considerato il caso con campo esterno longitudinale $h=0$ . Implementazione della matrice di adiacenza . Al fine di poter calcolare le osservabili termodinamiche di un sistema con connessioni random √® necessario implementare nell&#39;algoritmo un modo per rappresentare le connessioni attraverso una matrice di adiacenza. . Per farlo andremo ad aggiungere uno step alla costruzione dell&#39;Hamiltoniana in cui, data una matrice di adiacenza con alcuni elementi diversi da zero, andremo a controllare per ogni collegamento, se gli spin corrispondenti agli indici dell&#39;elemento diverso da zero sono concordi o discordi ed andremo ad aggiungere o togliere energia alla configurazione considerata. . La matrice di adiacenza essendo sparsa non verra considerata tutta, ma solo gli elementi diversi da zero, per velocizzare la compilazione. . Per verificare il giusto comportamento del nuovo codice, questo √® stato testato usando come matrice di adiacenza proprio quella relativa ad un reticolo 1D con connessioni a primi vicini, per poi essere confrontato con i risultati precedenti che devono risultare uguali. . Introduciamo quindi una funzione che genera le matrici di adiacenza relative a reticoli d-dimensionali aventi L elementi per lato: . def AdD(d,L): # This function returns the sparse adjacency matrix of a d-dimensonal # integer lattice with side L and the total number of elements L**d # Only for Periodic Boundary Conditions import scipy.sparse as ss N=L**d A=ss.dok_matrix((N,N)) for i in range(N): for j in range(d): A[i,(i+L**j)%N] = 1 A[i,(i-L**j)%N] = 1 return A.copy().tocoo(), N . E testiamo quindi il funzionamento del codice aggiornato per implementare le matrici di adiacenza: . #collapse %matplotlib inline import matplotlib.pyplot as plt import numpy as np import scipy.sparse.linalg as ssl import scipy.sparse as ss from scipy.sparse import lil_matrix hh=0 volte=100 volte+=1 lins=np.linspace(0,2,volte) linell=np.arange(6,10) nell=linell.size magniz=np.zeros((volte,nell)) Egs=np.zeros((volte+1,nell)) xi=np.zeros((volte+1,nell)) ci=np.zeros((volte+1,nell)) jay=-1/2 ell1=0 for ell in linell: ggg=0 NumTot=2**ell ev=np.zeros((volte,NumTot)) Psii=np.zeros((volte,NumTot)) net=AdD(1,ell)[0] coll=ss.find(net) for gg in lins: PBC=True # Costruisco la base iSpin=np.zeros((NumTot,ell)) for ii in range(NumTot): itemp=ii for jj in range(ell): iSpin[ii,jj]=np.floor(itemp%2) itemp=itemp/2 # Costruisco l&#39;Hamiltoniana HamOut=lil_matrix(np.zeros((NumTot,NumTot))) for iHam in range(len(coll[2])): for ii in range(NumTot): if iSpin[ii,coll[0][iHam]]==iSpin[ii,coll[1][iHam]]: HamOut[ii,ii]=HamOut[ii,ii] + jay else: HamOut[ii,ii]=HamOut[ii,ii] - jay # Sigma_x [transverse field] contorta ma torna: in pratica cambia lo spin al sito j for iHam in range(ell): for ii in range(NumTot): if iSpin[ii,iHam]==1: Exc = ii - 2**(iHam) else: Exc = ii + 2**(iHam) HamOut[int(Exc),ii] = HamOut[int(Exc),ii] + gg # Trovo l&#39;autostato del GS Egs[ggg,ell1]=ssl.eigsh(HamOut,1,which=&#39;SA&#39;)[0] Psi=ssl.eigsh(HamOut,1,which=&#39;SA&#39;)[1].T[0] Psii[ggg]=Psi.copy() # Calcolo la magnetizzazione MagX=np.zeros(ell) MagZ=np.zeros(ell) MagnetZ=0 for iSite in range(ell): Mx_sum=0 for ii in range(NumTot): if iSpin[ii,iSite] == 1: MagZ[iSite] = MagZ[iSite] + abs(Psi[ii])**2 Exc = ii -2**(iSite) else: MagZ[iSite] = MagZ[iSite] - abs(Psi[ii])**2 Exc = ii +2**(iSite) Mx_sum = Mx_sum + np.conjugate(Psi[ii]) * Psi[Exc] if abs(np.imag(Mx_sum))&gt;10**(-10): print(&quot;Non real magnetization&quot;) MagX[iSite] = np.real(Mx_sum) for ii in range(NumTot): Mag_ii = 0 for iSite in range(ell): if iSpin[ii,iSite] == 1: Mag_ii = Mag_ii + 1 else: Mag_ii = Mag_ii - 1 MagnetZ = MagnetZ + abs(Mag_ii)*(abs(Psi[ii])**2) magniz[ggg,ell1]=MagnetZ/ell xi[ggg,ell1]=-(magniz[ggg-1,ell1]-magniz[ggg,ell1])/(lins[ggg-1]-lins[ggg]) ci[ggg,ell1]=-(Egs[ggg-1,ell1]-Egs[ggg,ell1])/(lins[ggg-1]-lins[ggg]) ggg+=1 ell1+=1 magniz2=magniz Egs2=Egs xi2=xi ci2=ci plt.figure(figsize=(12, 9)) plt.subplot(221) plt.plot(lins[1:],magniz2[1:]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Magnetization&#39;) plt.subplot(222) plt.plot(lins[1:],Egs2[1:volte]) #plt.ylim(-1,1) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Energy&#39;) plt.subplot(223) plt.plot(lins[1:],xi2[1:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Susceptibility&#39;) plt.subplot(224) plt.plot(lins[1:],ci2[1:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Specific heat capacity&#39;) plt.show() . . I grafici rislutano identici a quelli precedenti ed insieme al Finite Size Scaling sotto ci conferma il corretto funzionamento del codice. . #collapse Fmagniz=np.zeros((volte,nell)) Fxi=np.zeros((volte+1,nell)) Flins=np.zeros((volte,nell)) ell1=0 for ell in linell: Fmagniz[:,ell1]=magniz2[:,ell1]*(ell)**(1/8) Fxi[:,ell1]=(xi2[:,ell1]/(ell))**(7/4) Flins[:,ell1]=(lins-1)*(ell) ell1+=1 plt.figure(figsize=(12,5)) plt.subplot(121) plt.plot(Flins[1:],Fmagniz[1:]) plt.xlabel(&#39;(g-gùñº) L&#39;) plt.ylabel(&#39;|Mz| L·µù&#39;) plt.subplot(122) plt.plot(Flins[1:],Fxi[1:volte]) plt.xlabel(&#39;(g-gùñº) L&#39;) plt.ylabel(&#39;œá L·µû&#39;) plt.show() . . Ora sfruttiamo questo stesso procedimento per studiare il modello di Ising quantistico 2D, usando la matrice di adiacenza opportuna, e confrontarlo con i risultati Monte-Carlo della relazione precedente per un Ising classico 3D, verificando il Quantum to Classical Mapping. . #collapse %matplotlib inline import matplotlib.pyplot as plt import numpy as np import scipy.sparse.linalg as ssl import scipy.sparse as ss from scipy.sparse import lil_matrix hh=0 volte=60 volte+=1 lins=np.linspace(0,6,volte) linell=np.arange(2,5) nell=linell.size magniz=np.zeros((volte,nell)) Egs=np.zeros((volte+1,nell)) xi=np.zeros((volte+1,nell)) ci=np.zeros((volte+1,nell)) jay=-1/2 ell1=0 for ell in linell: ggg=0 net=AdD(2,ell)[0] coll=ss.find(net) ell=ell*ell NumTot=2**ell ev=np.zeros((volte,NumTot)) Psii=np.zeros((volte,NumTot)) for gg in lins: PBC=True # Costruisco la base iSpin=np.zeros((NumTot,ell)) for ii in range(NumTot): itemp=ii for jj in range(ell): iSpin[ii,jj]=np.floor(itemp%2) itemp=itemp/2 # Costruisco l&#39;Hamiltoniana HamOut=lil_matrix(np.zeros((NumTot,NumTot))) for iHam in range(len(coll[2])): for ii in range(NumTot): if iSpin[ii,coll[0][iHam]]==iSpin[ii,coll[1][iHam]]: HamOut[ii,ii]=HamOut[ii,ii] + jay else: HamOut[ii,ii]=HamOut[ii,ii] - jay # Sigma_x [transverse field] contorta ma torna: in pratica cambia lo spin al sito j for iHam in range(ell): for ii in range(NumTot): if iSpin[ii,iHam]==1: Exc = ii - 2**(iHam) else: Exc = ii + 2**(iHam) HamOut[int(Exc),ii] = HamOut[int(Exc),ii] + gg # Trovo l&#39;autostato del GS Egs[ggg,ell1]=ssl.eigsh(HamOut,1,which=&#39;SA&#39;)[0] Psi=ssl.eigsh(HamOut,1,which=&#39;SA&#39;)[1].T[0] Psii[ggg]=Psi.copy() # Calcolo la magnetizzazione MagX=np.zeros(ell) MagZ=np.zeros(ell) MagnetZ=0 for iSite in range(ell): Mx_sum=0 for ii in range(NumTot): if iSpin[ii,iSite] == 1: MagZ[iSite] = MagZ[iSite] + abs(Psi[ii])**2 Exc = ii -2**(iSite) else: MagZ[iSite] = MagZ[iSite] - abs(Psi[ii])**2 Exc = ii +2**(iSite) Mx_sum = Mx_sum + np.conjugate(Psi[ii]) * Psi[Exc] if abs(np.imag(Mx_sum))&gt;10**(-10): print(&quot;Non real magnetization&quot;) MagX[iSite] = np.real(Mx_sum) for ii in range(NumTot): Mag_ii = 0 for iSite in range(ell): if iSpin[ii,iSite] == 1: Mag_ii = Mag_ii + 1 else: Mag_ii = Mag_ii - 1 MagnetZ = MagnetZ + abs(Mag_ii)*(abs(Psi[ii])**2) magniz[ggg,ell1]=MagnetZ/ell xi[ggg,ell1]=-(magniz[ggg-1,ell1]-magniz[ggg,ell1])/(lins[ggg-1]-lins[ggg]) ci[ggg,ell1]=-(Egs[ggg-1,ell1]-Egs[ggg,ell1])/(lins[ggg-1]-lins[ggg]) ggg+=1 ell1+=1 magniz3=magniz Egs3=Egs xi3=xi ci3=ci plt.figure(figsize=(12, 9)) plt.subplot(221) plt.plot(lins[1:],magniz3[1:]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Magnetization&#39;) plt.subplot(222) plt.plot(lins[1:],Egs3[1:volte]) #plt.ylim(-1,1) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Energy&#39;) plt.subplot(223) plt.plot(lins[1:],xi3[1:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Susceptibility&#39;) plt.subplot(224) plt.plot(lins[1:],ci3[1:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Specific heat capacity&#39;) plt.show() . . #collapse Fmagniz=np.zeros((volte,nell)) Fxi=np.zeros((volte+1,nell)) Flins=np.zeros((volte,nell)) ell1=0 for ell in linell: Fmagniz[:,ell1]=magniz3[:,ell1]*(ell)**(0.326419) Fxi[:,ell1]=(xi3[:,ell1]/(ell))**(1.237075) Flins[:,ell1]=(lins-3.8)*(ell) ell1+=1 plt.figure(figsize=(12,5)) plt.subplot(121) plt.plot(Flins[1:],Fmagniz[1:]) plt.xlabel(&#39;(g-gùñº) L&#39;) plt.ylabel(&#39;|Mz| L·µù&#39;) plt.subplot(122) plt.plot(Flins[1:],Fxi[1:volte]) plt.xlabel(&#39;(g-gùñº) L&#39;) plt.ylabel(&#39;œá L·µû&#39;) plt.show() . . Vabb√®, non viene bene ma il numero di siti per lato √® bassissimo. . Studio di sistemi con connessioni random . Passiamo dunque ora allo studio di un sistema le cui connessioni tra elementi sono rappresentate da una matrice di adiacenza random, ovvero in cui gli elementi della matrice diversi da zero sono disposti in maniera casuale all&#39;interno della matrice stessa. La matrice di adiacenza √® data da una funzione delle libreria SciPy che prende in input le dimensioni della matrice e la densit√† di elementi diversi da zero che si vuole ottenere. Per esempio per un sistema di 10 elementi come quello seguente, prendendo in input i valori (10, 10, 0.2) la funzione rand() restituisce una matrice 10x10 con 20 elementi diversi da zero scelti a caso. . Poich√® per gli stessi valori di input la funzione restituisce realizzazioni diverse di sistemi con le stesse caratteristiche, per avere un comportamento generale verranno calcolate varie realizzazioni di sistemi con gli stessi parametri e i valori di output verranno mediate fra tutte le realizzazioni. Il grafico della media √® evidenziato in blu. . #collapse %matplotlib inline import matplotlib.pyplot as plt import numpy as np import scipy.sparse.linalg as ssl import scipy.sparse as ss from scipy.sparse import lil_matrix hh=0 volte=60 volte+=1 lins=np.linspace(0,3,volte) linum=np.arange(20) nell=linum.size magniz=np.zeros((volte,nell)) Egs=np.zeros((volte+1,nell)) xi=np.zeros((volte+1,nell)) ci=np.zeros((volte+1,nell)) jay=-1/2 ell=10 ell1=0 for numer in linum: ggg=0 NumTot=2**ell ev=np.zeros((volte,NumTot)) Psii=np.zeros((volte,NumTot)) net=ss.rand(ell,ell,2/ell) # Matrice di Adiacenza Random coll=ss.find(net) for gg in lins: PBC=True # Costruisco la base iSpin=np.zeros((NumTot,ell)) for ii in range(NumTot): itemp=ii for jj in range(ell): iSpin[ii,jj]=np.floor(itemp%2) itemp=itemp/2 # Costruisco l&#39;Hamiltoniana HamOut=lil_matrix(np.zeros((NumTot,NumTot))) for iHam in range(len(coll[2])): for ii in range(NumTot): if iSpin[ii,coll[0][iHam]]==iSpin[ii,coll[1][iHam]]: HamOut[ii,ii]=HamOut[ii,ii] + jay else: HamOut[ii,ii]=HamOut[ii,ii] - jay # Sigma_x [transverse field] contorta ma torna: in pratica cambia lo spin al sito j for iHam in range(ell): for ii in range(NumTot): if iSpin[ii,iHam]==1: Exc = ii - 2**(iHam) else: Exc = ii + 2**(iHam) HamOut[int(Exc),ii] = HamOut[int(Exc),ii] + gg # Trovo l&#39;autostato del GS Egs[ggg,ell1]=ssl.eigsh(HamOut,1,which=&#39;SA&#39;)[0] Psi=ssl.eigsh(HamOut,1,which=&#39;SA&#39;)[1].T[0] Psii[ggg]=Psi.copy() # Calcolo la magnetizzazione MagX=np.zeros(ell) MagZ=np.zeros(ell) MagnetZ=0 for iSite in range(ell): Mx_sum=0 for ii in range(NumTot): if iSpin[ii,iSite] == 1: MagZ[iSite] = MagZ[iSite] + abs(Psi[ii])**2 Exc = ii -2**(iSite) else: MagZ[iSite] = MagZ[iSite] - abs(Psi[ii])**2 Exc = ii +2**(iSite) Mx_sum = Mx_sum + np.conjugate(Psi[ii]) * Psi[Exc] if abs(np.imag(Mx_sum))&gt;10**(-10): print(&quot;Non real magnetization&quot;) MagX[iSite] = np.real(Mx_sum) for ii in range(NumTot): Mag_ii = 0 for iSite in range(ell): if iSpin[ii,iSite] == 1: Mag_ii = Mag_ii + 1 else: Mag_ii = Mag_ii - 1 MagnetZ = MagnetZ + abs(Mag_ii)*(abs(Psi[ii])**2) magniz[ggg,ell1]=MagnetZ/ell xi[ggg,ell1]=-(magniz[ggg-1,ell1]-magniz[ggg,ell1])/(lins[ggg-1]-lins[ggg]) ci[ggg,ell1]=-(Egs[ggg-1,ell1]-Egs[ggg,ell1])/(lins[ggg-1]-lins[ggg]) #Ezero[ell//2-2]=Egs[20] ggg+=1 ell1+=1 magniz5=magniz Egs5=Egs xi5=xi ci5=ci plt.figure(figsize=(12, 9)) plt.subplot(221) plt.plot(lins[1:],magniz5[1:]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Magnetization&#39;) plt.subplot(221) plt.plot(lins[1:],np.sum(magniz5[1:,1:],axis=1)/magniz5[1:].shape[1],color=&#39;b&#39;, linewidth=3.0) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Magnetization&#39;) plt.subplot(222) plt.plot(lins[1:],Egs5[1:volte]) #plt.ylim(-1,1) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Energy&#39;) plt.subplot(223) plt.plot(lins[2:],xi5[2:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Susceptibility&#39;) plt.subplot(223) plt.plot(lins[2:],np.sum(xi5[3:,2:volte],axis=1)/xi5[2:volte].shape[1],color=&#39;b&#39;, linewidth=3.0) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Susceptibility&#39;) plt.subplot(224) plt.plot(lins[1:],ci5[1:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Specific heat capacity&#39;) plt.show() . . /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:127: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:143: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. . Per tutte le realizzazioni si osserva un punto di transizione di fase per valori di $g$ intorno ad 1 con una media poco superiore ad 1. . Il sistema precedente aveva come densit√† di elemeti diversi da zero $d=0.2$. √à possibile che il valore del punto di transizione dipenda da questo valore? Per rispondere a questa domanda possiamo procedere con uno studio delle medie di varie realizzazioni con densit√† variabili da 0.1 a 1, poich√® il caso $d=0$ √® banale e corrisponde ad un sistema senza interazioni e quindi senza magnetizzazione. . #collapse %matplotlib inline import matplotlib.pyplot as plt import numpy as np import scipy.sparse.linalg as ssl import scipy.sparse as ss from scipy.sparse import lil_matrix hh=0 volte=100 volte+=1 nrip=5 lins=np.linspace(0,10,volte) linum=np.arange(1,10) nell=linum.size magnizR=np.zeros((volte,nell,nrip)) EgsR=np.zeros((volte+1,nell,nrip)) xiR=np.zeros((volte+1,nell,nrip)) ciR=np.zeros((volte+1,nell,nrip)) jay=-1/2 ell=9 ell1=0 for numer in linum: NumTot=2**ell ev=np.zeros((volte,NumTot)) Psii=np.zeros((volte,NumTot)) net=ss.rand(ell,ell,numer/ell) # Matrice di Adiacenza Random coll=ss.find(net) for rip in range(nrip): ggg=0 for gg in lins: # Costruisco la base iSpin=np.zeros((NumTot,ell)) for ii in range(NumTot): itemp=ii for jj in range(ell): iSpin[ii,jj]=np.floor(itemp%2) itemp=itemp/2 # Costruisco l&#39;Hamiltoniana HamOut=lil_matrix(np.zeros((NumTot,NumTot))) for iHam in range(len(coll[2])): for ii in range(NumTot): if iSpin[ii,coll[0][iHam]]==iSpin[ii,coll[1][iHam]]: HamOut[ii,ii]=HamOut[ii,ii] + jay else: HamOut[ii,ii]=HamOut[ii,ii] - jay # Sigma_x [transverse field] contorta ma torna: in pratica cambia lo spin al sito j for iHam in range(ell): for ii in range(NumTot): if iSpin[ii,iHam]==1: Exc = ii - 2**(iHam) else: Exc = ii + 2**(iHam) HamOut[int(Exc),ii] = HamOut[int(Exc),ii] + gg # Trovo l&#39;autostato del GS EgsR[ggg,ell1,rip]=ssl.eigsh(HamOut,1,which=&#39;SA&#39;)[0] Psi=ssl.eigsh(HamOut,1,which=&#39;SA&#39;)[1].T[0] Psii[ggg]=Psi.copy() # Calcolo la magnetizzazione MagX=np.zeros(ell) MagZ=np.zeros(ell) MagnetZ=0 for iSite in range(ell): Mx_sum=0 for ii in range(NumTot): if iSpin[ii,iSite] == 1: MagZ[iSite] = MagZ[iSite] + abs(Psi[ii])**2 Exc = ii -2**(iSite) else: MagZ[iSite] = MagZ[iSite] - abs(Psi[ii])**2 Exc = ii +2**(iSite) Mx_sum = Mx_sum + np.conjugate(Psi[ii]) * Psi[Exc] if abs(np.imag(Mx_sum))&gt;10**(-10): print(&quot;Non real magnetization&quot;) MagX[iSite] = np.real(Mx_sum) for ii in range(NumTot): Mag_ii = 0 for iSite in range(ell): if iSpin[ii,iSite] == 1: Mag_ii = Mag_ii + 1 else: Mag_ii = Mag_ii - 1 MagnetZ = MagnetZ + abs(Mag_ii)*(abs(Psi[ii])**2) magnizR[ggg,ell1,rip]=MagnetZ/ell xiR[ggg,ell1,rip]=-(magnizR[ggg-1,ell1,rip]-magnizR[ggg,ell1,rip])/(lins[ggg-1]-lins[ggg]) ciR[ggg,ell1,rip]=-(EgsR[ggg-1,ell1,rip]-EgsR[ggg,ell1,rip])/(lins[ggg-1]-lins[ggg]) ggg+=1 magniz6=np.mean(magnizR,axis=2) Egs6=np.mean(EgsR,axis=2) xi6=np.mean(xiR,axis=2) ci6=np.mean(ciR,axis=2) ell1+=1 plt.figure(figsize=(12, 9)) plt.subplot(221) plt.plot(lins[1:],magniz6[1:]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Magnetization&#39;) plt.subplot(222) plt.plot(lins[1:],Egs6[1:volte]) #plt.ylim(-1,1) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Energy&#39;) plt.subplot(223) plt.plot(lins[2:],xi6[2:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Susceptibility&#39;) plt.subplot(224) plt.plot(lins[1:],ci6[1:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Specific heat capacity&#39;) plt.show() . . plt.figure(figsize=(12, 9)) plt.subplot(221) plt.plot(lins[1:],magniz6[1:]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Magnetization&#39;) plt.subplot(222) plt.plot(lins[1:],Egs6[1:volte]) #plt.ylim(-1,1) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Energy&#39;) plt.subplot(223) plt.plot(lins[2:],xi6[2:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Susceptibility&#39;) plt.subplot(224) plt.plot(lins[1:],ci6[1:volte]) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Specific heat capacity&#39;) plt.show() . Studiamo adesso il comportamento di un sistema di Ising quantistico 1D a cui aggiungiamo interazioni a lungo raggio random come quelle studiate sopra. Osserveremo il comportamento di questo sistema considerando le interazioni a lungo raggio prima ferromagnetiche poi antiferromagnetiche. .",
            "url": "https://edoarder.github.io/Metodi_Numerici/2020/06/07/Random_Network_Diagonalization-2.html",
            "relUrl": "/2020/06/07/Random_Network_Diagonalization-2.html",
            "date": " ‚Ä¢ Jun 7, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Modulo 5",
            "content": "A differenza dei precedenti moduli in questa relazione non mi occuper√≤ di studiare sistemi con interazioni a lunga distanza random poich√© il DMRG si basa fondamentalmente su interazioni a primi vicini. Sono possibili estensioni per considerare interazioni a lungo raggio, ma richiedono un notevole sforzo sia di implementazione che computazionale. Studier√≤ comunque il comportamento di una catena unidimensionale tipo Ising, ma considerando i valori delle costanti di accoppiamento dipendenti dalla posizione del sito rispetto alla catena, con valori random. . La Density Matrix Renormalization Group √® una tecnica numerica iterativa che consente di trovare il ground state, ed eventualmente pochi altri stati eccitati, di un sistema quantistico a bassa dimensionalit√† in una maniera estremamente efficiente. √à un metodo approssimato che si ispira alla rinormalizzazione numerica alla Wilson, ma il cui funzionamento si basa sull&#39;entanglement bipartito per il ground state di $ hat{H}$. Se l&#39;Hamiltoniana del sistema pu√≤ essere scritta come somma di termini locali riferiti ad un sito e ai suoi primi vicini e nel caso in cui il Ground State risulti non degenere, per il caso unidimensionale √® dimostrata la validit√† dell&#39;Area Law: considerando uno stato puro $| psi‚ü©_{AB}$ di un sistema quantistico bipartito AB, questa propriet√† esprime la dipendenza dell&#39;entropia di Von Neumann della partizione A dalla dimensione del confine tra A e B. $$ S( rho_A) sim dim(bound(A|B))$$ in cui $$ rho_A = Tr_B(| psi‚ü©_{AB}‚ü® psi|)$$ . Una generica Hamiltoniana che soddisfa queste condizioni pu√≤ essere scritta come: . $$ hat{H}= sum_{i=1}^L ( sum_ alpha J_i^{( alpha)} hat{S}_i^{( alpha)} hat{T}_{i+1}^{( alpha)} + sum_ beta B_i^{( beta)} hat{V}_i^{( beta)} ) $$ . dove gli $J_i^{( alpha)}$ e i $B_i^{( beta)}$ sono le costanti di accoppiamento mentre i $ { hat{S}_i^{( alpha)} }$, $ { hat{T}_{i+1}^{( alpha)} }$ e $ { hat{V}_i^{( beta)} }$ sono operatori agenti sul sito i-esimo, mentre $ alpha$ e $ beta$ sono le varie componenti degli operatori. . L&#39;Hamiltoniana del modello di Ising quantistico 1D rientra in questa forma: . $$ hat{H} = - sum_{i}^{L-1} J_{i} sigma_i^z sigma_{i+1}^z - sum_{i}^L g_i sigma_i^x - sum_{i}^L h_i sigma_i^z$$ . dove le varie $ sigma_i$ sono gli operatori di spin agenti sul sito i-esmi che, nella base canonica, sono rappresentati dalle matrici di Pauli. . L&#39;algoritmo DMRG Infinite-System si articola in alcuni step: . Si parte da un blocco $B(1,d)$, composto dal solo sito estremo di sinistra, di cui si definisce l&#39;Hamiltoniana $ hat{H}_B$, nel codice BlockH. Spazio di Hilbert di dimensione $d$. . | Si costruisce l&#39;Enlarged Block aggiungendo al blocco precedente il sito adiacente destro e si costruisce l&#39;hamiltoniana corrispondente $ hat{H}_E$: $$ hat{H}_E = hat{H}_B otimes mathbb{1}_{sito} + mathbb{1}_B otimes hat{H}_{sito} + hat{H}_{B-sito} $$ Spazio di Hilbert di dimensione $d^2$. . | Si costruisce il Super-block aggiundendo al blocco precedente un blocco speculare, considerando il fatto che il sistema in esame √® simmetrico per riflessione rispetto al centro della catena, il collegamento √® dato dall&#39;interazione dei due siti esterni aggiunti al passo precedente. L&#39;Hamiltoniana del Super-block diventa: $$ hat{H}_{SB} = hat{H}_E otimes mathbb{1}_{E&#39;} + mathbb{1}_E otimes hat{H}_{E&#39;} + hat{H}_{E-E&#39;} $$ La cui dimensione √® $d^4$. . | Si trova l&#39;autovalore minore ed il corrispondente autovettore di $ hat{H}_{SB}$, ovvero il Ground State $| psi_{gs}‚ü©$ e la sua energia $E_{gs}$. . | Si calcola la matrice di densit√† ridotta $ rho_L$ relativa al blocco di sinistra: $ rho_L=Tr_R | psi_{gs}‚ü©‚ü® psi_{gs}|$ che operativamente nel codice √® stato implementato calcolando $ rho_L= psi_{gs} psi_{gs}^ dagger$. . | Si diagonalizza $ rho_L$ ordinando gli autovalori $ lambda_i$ in senso decrescente e si ricava la rappresentazione della matrice densit√†: $$ rho_L = sum_{i=1}^{d^2} lambda_i |w_i‚ü©‚ü®w_i| $$ dove $|w_i‚ü©$ √® l&#39;autovettore corrispondente all&#39;autovalore $ lambda_i$. . | Di questi stati si tengono soltalto i primi $m$, corrispondenti agli autovalori $ lambda_i$ maggiori. $m$ √® scelto come il minimo tra la dimensione dello spazio di Hilbert del sistema e un valore fissato all&#39;inizio dell&#39;algoritmo, che rappresenta la dimensione massima dello spazio di Hilbert del sistema approssimato. Da questi $m$ autovettori si costruiscono due matrici $O$ e $O^ dagger$ diaponendoli rispettivamente per colonne e per righe. $O$ e $O^ dagger$ non sono matrici quadrate e servono appunto per troncare la matrice dell&#39;Hamiltoniana. . | L&#39;ultimo step √® infatti quello di calcolare la matrice hamiltoniana dell&#39;Enlarged Block nella base troncata attraverso: $$ tilde{H}_E=O^ dagger H_E O$$ Si rinormalizzano inoltre anche gli altri operatori che serviranno per il ciclo successivo. . | Nel ciclo successivo dell&#39;algoritmo sar√† dunque utilizzato l&#39;Enlarged Block rinormalizzato come nuovo blocco di partenza, chiamato $B(2,m)$, e per procedere con l&#39;algoritmo saranno utilizzati gli altri operatori rinormalizzati. . #collapse %matplotlib inline import matplotlib.pyplot as plt import numpy as np import scipy.sparse.linalg as ssl import scipy.sparse as ss . . Per tutti i modelli presentati si considereranno le condizioni al bordo aperte. . L&#39;osservabile di cui andremo a studiare l&#39;andamento per ogni tipo di modello √® l&#39;entropia di Von Neumann definita come: $$ S( rho) = -Tr[ rho log( rho)] = - sum_i lambda_i log( lambda_i)$$ . Infinite-System DMRG per il modello di Ising . Di seguito √® presentato il codice che implementa l&#39;Infinite-System DMRG per un modello di Ising quantistico 1D. Il codice restituisce i grafici dell&#39;andamento dell&#39;entropia al variare dell&#39;intensit√† del campo trasverso, parametrizzato da $g$ che varia da 0 a 2. Per ogni run dell&#39;algoritmo $J_i=J$ e $g_i=g$ sono costanti e $h_i=0$ $ forall i$. Poich√® il comportamente del sistema non dipende da entrambe le variabili diverse da zero, ma solo dal loro rapporto, consideriamo $J=1$. Ad ogni grafico corrisponde una diversa taglia del sistema descritta in legenda. . m=9 # Dimensione massima dello spazio di Hilbert del sistema approssimato NIter=200 # Numero di iterazioni dell&#39;algoritmo rep=50 # Numero di punti del grafico rep+=1 gmax=1.02 ling=np.linspace(0.94,gmax,rep) linell=2**np.arange(3,8) Evec=np.zeros(rep) Entropy=np.zeros(rep) graphs=np.zeros((rep,NIter)) # inizializzazione degli operatori I=np.eye(2,2) Sz=np.array([[1, 0],[0,-1]]) Sx=np.array([[0, 1],[1,0]]) ggg=0 for g in ling: #blocchi iniziali BlockSz = Sz BlockSx = Sx BlockI = I BlockH = g*Sx Energy = 0 for l in range(NIter): SystSize = 2*l + 4 # Get the 2m-dimensional operators for the block + site BlockH = np.kron(BlockH, I) + np.kron(BlockI, g*Sx) - np.kron(BlockSz, Sz) BlockSz = np.kron(BlockI, Sz) BlockSx = np.kron(BlockI, Sx) BlockI = np.kron(BlockI, I) # Matrice dell&#39;Hamiltoniana per il Super-Blocco H_super = np.kron(BlockH, BlockI) + np.kron(BlockI, BlockH) - np.kron(BlockSz, BlockSz) H_super = 0.5 * (H_super + H_super.T); # ensure H is symmetric # Diagonalizzazione dell&#39;Hamiltoniana LastEnergy = Energy Energy= ssl.eigsh(H_super,1,which=&#39;SA&#39;)[0] #[0] Psi = ssl.eigsh(H_super,1,which=&#39;SA&#39;)[1].T #[0] EnergyPerBond = (Energy - LastEnergy) / 2 Ener2 = Energy / SystSize # Sigma = Psi&#39; *kron(BlockSz,BlockSz) * Psi; % n.n. ZZ correlation function # Costruzione della matrice densit√† nr=Psi.size Dim = int(np.sqrt(nr)) PsiMatrix = np.reshape(Psi,(Dim,Dim)) Rho = PsiMatrix @ PsiMatrix.T # Diagonalizzazione della matrice densit√† D,V = np.linalg.eigh(Rho) D=D[::-1] # descending Index=np.arange(Dim) Index=Index[::-1] V=V[:,Index] # Construzione dell&#39;operatore di troncamento NKeep = min(D.size, m) Omatr = V[:,:NKeep] TruncationError = 1 - sum(D[:NKeep]) Ent=-sum(D[:NKeep]*np.log(D[:NKeep])) # Trasformazione degli operatori dei blocchi nella base troncata BlockH = Omatr.T @ BlockH @ Omatr BlockSz = Omatr.T @ BlockSz @ Omatr BlockSx = Omatr.T @ BlockSx @ Omatr BlockI = Omatr.T @ BlockI @ Omatr graphs[ggg,l]=Ent ell=SystSize Evec[ggg]=Energy Entropy[ggg]=Ent ggg+=1 for i in range(5,11): plt.plot(ling,graphs[:,2*i*10-1],label=2*i*10) plt.legend() plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Entropy&#39;) plt.show() . Si pu√≤ notare come all&#39;aumentare della taglia il valore di $g$ corrispondente al picco dell&#39;entropia converga ad 1, come previsto teoricamente, ed il picco si alzi diventando sempre pi√π stretto, indicando nel limite termodinamico una transizione di fase. Per valori di $g$ maggiori di 1 l&#39;entropia si assesta ad un valore maggiore di zero, effetto delle condizioni al bordo aperte. . Interazioni a valori random . Di seguito √® riportato il grafico, ed il codice espandibile, di un modello di Ising 1D in cui i valori di $J_i$ non sono tutti uguali ad 1, ma sono estratti random da una distribuzione normale con media 1 e varianza 0.3 in questo caso. Ad ogni ciclo sono estratti due numeri random, dalla stessa distribuzione, uno per l&#39;interazione Blocco-Sito ed uno per l&#39;interazione tra due Enlarged Block. . #collapse m=8 NIter=200 rep=40 rep+=1 gmax=2 ling=np.linspace(0,gmax,rep) Evec=np.zeros(rep) Entropy=np.zeros(rep) ggg=0 # inizialize local ops I=np.eye(2,2) Sz=np.array([[1, 0],[0,-1]]) Sx=np.array([[0, 1],[1,0]]) # initial blocks for gm in ling: Ent=0 BlockSz = Sz BlockSx = Sx BlockI = I BlockH = gm*Sx Energy = 0 for l in range(NIter): SystSize = 2*l + 4 g=gm j1=np.random.default_rng().normal(1, .3) # Get the 2m-dimensional operators for the block + site BlockH = np.kron(BlockH, I) + np.kron(BlockI, g*Sx) - j1*np.kron(BlockSz, Sz) BlockSz = np.kron(BlockI, Sz) BlockSx = np.kron(BlockI, Sx) BlockI = np.kron(BlockI, I) # HAMILTONIAN MATRIX for superblock j2=np.random.default_rng().normal(1, .3) H_super = np.kron(BlockH, BlockI) + np.kron(BlockI, BlockH) - j2*np.kron(BlockSz, BlockSz) H_super = 0.5 * (H_super + H_super.T); # ensure H is symmetric # Diagonalizing the Hamiltonian LastEnergy = Energy Energy= ssl.eigsh(H_super,1,which=&#39;SA&#39;)[0] #[0] Psi = ssl.eigsh(H_super,1,which=&#39;SA&#39;)[1].T #[0] EnergyPerBond = (Energy - LastEnergy) / 2 Ener2 = Energy / SystSize # Sigma = Psi&#39; *kron(BlockSz,BlockSz) * Psi; % n.n. ZZ correlation function # Form the reduced density matrix nr=Psi.size Dim = int(np.sqrt(nr)) PsiMatrix = np.reshape(Psi,(Dim,Dim)) Rho = PsiMatrix @ PsiMatrix.T # Diagonalize the density matrix D,V = np.linalg.eigh(Rho) D=D[::-1] # descending Index=np.arange(Dim) Index=Index[::-1] V=V[:,Index] # Construct the truncation operator NKeep = min(D.size, m) Omatr = V[:,:NKeep] TruncationError = 1 - sum(D[:NKeep]) # Transform the block operators into the truncated basis BlockH = Omatr.T @ BlockH @ Omatr BlockSz = Omatr.T @ BlockSz @ Omatr BlockSx = Omatr.T @ BlockSx @ Omatr BlockI = Omatr.T @ BlockI @ Omatr Ent=-sum(D[:NKeep]*np.log(D[:NKeep])) #Evec[ggg]=Energy Entropy[ggg]=Ent ggg+=1 plt.plot(ling,Entropy) plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Entropy&#39;) plt.show() . . Si pu√≤ notare come l&#39;andamento del grafico non si discosti troppo da quello del caso precedente. Risulta infatti un esserci una prima zona, per bassi valori di $g$, in cui l&#39;entropia √® piccola, un rapido aumento ed un picco nei pressi di $g=1$, in seguito un decremento ed un assestamento sempre dovuto alle condizioni al bordo aperte. Risultano evidenti comunque molte fluttuazioni lungo il grafico, effetto dovuto appunto alle interazioni tra primi vicini a valori random. . Bisogna comunque sottolineare che per ogni valore di $g$ l&#39;entropia calcolata si riferisce ad una catena con valori $J_i$ indipendenti dalle altre catene a diversi di $g$, per ogni valore di $g$ √® necessario infatti calcolare una Hamiltoniana che ha $J_i$ completamente nuovi e questo giustifica in parte le grandi oscillazioni che si possono osservare. . Un altro motivo, che verr√† studiato meglio nel proseguo della relazione, consiste nel fatto che per una catena di Ising &quot;normale&quot; il punto di transizioni si ha, come detto in precedenza, per valori di $g$ e $J$ tali che $g/J=1$, quindi delle fluttuazioni su $J$ possono comportare grandi fluttuazioni sull&#39;entropia finale del sistema. . Fluttuazioni mediate . Al fine di diminuire le fluttuazioni presenti in ogni grafico in modo da ricavare dei comportamenti generali, sono state calcolate varie realizzazioni di catene di Ising con interazioni a valori random aventi la stessa media 1 e la stessa varianza 0.3, per poi calcolarne la media, evidenziata con un tratto nero pi√π spesso. . #collapse m=10 NIter=200 rep=30 rep+=1 gmax=1.5 ling=np.linspace(0.5,gmax,rep) nrip=8 Evec=np.zeros((rep,nrip)) Entropy=np.zeros((rep,nrip)) ggg=0 # inizialize local ops I=np.eye(2,2) Sz=np.array([[1, 0],[0,-1]]) Sx=np.array([[0, 1],[1,0]]) # initial blocks for gm in ling: for rip in range(nrip): BlockSz = Sz BlockSx = Sx BlockI = I BlockH = gm*Sx Energy = 0 for l in range(NIter): SystSize = 2*l + 4 g=gm j1=np.random.default_rng().normal(1, .3) # Get the 2m-dimensional operators for the block + site BlockH = np.kron(BlockH, I) + np.kron(BlockI, g*Sx) - j1*np.kron(BlockSz, Sz) BlockSz = np.kron(BlockI, Sz) BlockSx = np.kron(BlockI, Sx) BlockI = np.kron(BlockI, I) # HAMILTONIAN MATRIX for superblock j2=np.random.default_rng().normal(1, .3) H_super = np.kron(BlockH, BlockI) + np.kron(BlockI, BlockH) - j2*np.kron(BlockSz, BlockSz) H_super = 0.5 * (H_super + H_super.T); # ensure H is symmetric # Diagonalizing the Hamiltonian LastEnergy = Energy Energy= ssl.eigsh(H_super,1,which=&#39;SA&#39;)[0] #[0] Psi = ssl.eigsh(H_super,1,which=&#39;SA&#39;)[1].T #[0] EnergyPerBond = (Energy - LastEnergy) / 2 Ener2 = Energy / SystSize # Sigma = Psi&#39; *kron(BlockSz,BlockSz) * Psi; % n.n. ZZ correlation function # Form the reduced density matrix nr=Psi.size Dim = int(np.sqrt(nr)) PsiMatrix = np.reshape(Psi,(Dim,Dim)) Rho = PsiMatrix @ PsiMatrix.T # Diagonalize the density matrix D,V = np.linalg.eigh(Rho) D=D[::-1] # descending Index=np.arange(Dim) Index=Index[::-1] V=V[:,Index] # Construct the truncation operator NKeep = min(D.size, m) Omatr = V[:,:NKeep] TruncationError = 1 - sum(D[:NKeep]) # Transform the block operators into the truncated basis BlockH = Omatr.T @ BlockH @ Omatr BlockSz = Omatr.T @ BlockSz @ Omatr BlockSx = Omatr.T @ BlockSx @ Omatr BlockI = Omatr.T @ BlockI @ Omatr Ent=-sum(D[:NKeep]*np.log(D[:NKeep])) Evec[ggg,rip]=Energy Entropy[ggg,rip]=Ent ggg+=1 plt.plot(ling[1:],Entropy[1:]) plt.plot(ling[1:],np.sum(Entropy[1:],axis=1)/nrip,color=&#39;k&#39;, linewidth=2.0) plt.show() . . Nonostante la permanenza di fluttuazioni importanti del grafico possiamo notare come la forma generale resti sostanzialmente invariata, ma possiamo osservare uno spostamento del picco verso sinistra, effetto non dovuto alla statistica, in quanto altre simulazioni, come mostrato sotto, portano alle stesse conclusioni. . Comportamento per diverse varianze . √à possibile quindi pensare ad una correlazione tra la varianza della distribuzione da cui viengono estratti i $J_i$ e la posizione del picco dell&#39;entropia? . Per rispondere a questa domanda sono state calcolate le medie di molte realizzazioni di catene di Ising con interazioni a valori random, corrispondenti a diversi valori di varianze, che vanno da 0.1 ad 1. . Di seguito sono riportati i grafici, insieme al codice espandibile, dell&#39;andamento dell&#39;entropia in funzione del parametro $g$, per i diversi valori della varianza. . #collapse m=8 NIter=200 rep=40 rep+=1 gmax=1.5 Nmedie=4 ling=np.linspace(0.5,gmax,rep) linsig=np.linspace(0.1,1,Nmedie) nrip=20 #ling=ling[int(30*rep/100):] Evec=np.zeros((rep,nrip)) Entropy=np.zeros((rep,nrip)) MEnt=np.zeros((Nmedie,rep-1)) ggg=0 # inizialize local ops I=np.eye(2,2) Sz=np.array([[1, 0],[0,-1]]) Sx=np.array([[0, 1],[1,0]]) # initial blocks sss=0 for sig in linsig: ggg=0 for gm in ling: for rip in range(nrip): BlockSz = Sz BlockSx = Sx BlockI = I BlockH = gm*Sx Energy = 0 for l in range(NIter): SystSize = 2*l + 4 g=gm j1=np.random.default_rng().normal(1, sig) # Get the 2m-dimensional operators for the block + site BlockH = np.kron(BlockH, I) + np.kron(BlockI, g*Sx) - j1*np.kron(BlockSz, Sz) BlockSz = np.kron(BlockI, Sz) BlockSx = np.kron(BlockI, Sx) BlockI = np.kron(BlockI, I) # HAMILTONIAN MATRIX for superblock j2=np.random.default_rng().normal(1, sig) H_super = np.kron(BlockH, BlockI) + np.kron(BlockI, BlockH) - j2*np.kron(BlockSz, BlockSz) H_super = 0.5 * (H_super + H_super.T); # ensure H is symmetric # Diagonalizing the Hamiltonian LastEnergy = Energy Energy= ssl.eigsh(H_super,1,which=&#39;SA&#39;)[0] #[0] Psi = ssl.eigsh(H_super,1,which=&#39;SA&#39;)[1].T #[0] EnergyPerBond = (Energy - LastEnergy) / 2 Ener2 = Energy / SystSize # Sigma = Psi&#39; *kron(BlockSz,BlockSz) * Psi; % n.n. ZZ correlation function # Form the reduced density matrix nr=Psi.size Dim = int(np.sqrt(nr)) PsiMatrix = np.reshape(Psi,(Dim,Dim)) Rho = PsiMatrix @ PsiMatrix.T # Diagonalize the density matrix D,V = np.linalg.eigh(Rho) D=D[::-1] # descending Index=np.arange(Dim) Index=Index[::-1] V=V[:,Index] # Construct the truncation operator NKeep = min(D.size, m) Omatr = V[:,:NKeep] TruncationError = 1 - sum(D[:NKeep]) # Transform the block operators into the truncated basis BlockH = Omatr.T @ BlockH @ Omatr BlockSz = Omatr.T @ BlockSz @ Omatr BlockSx = Omatr.T @ BlockSx @ Omatr BlockI = Omatr.T @ BlockI @ Omatr #print(SystSize, Energy, EnergyPerBond, Ener2, TruncationError) Ent=-sum(D[:NKeep]*np.log(D[:NKeep])) #Evec[ggg,rip]=Energy Entropy[ggg,rip]=Ent ggg+=1 MEnt[sss]=np.sum(Entropy[1:],axis=1)/nrip sss+=1 #Spectrum=ssl.eigsh(H_super)[0] for i in range(4): plt.plot(ling[1:],MEnt[i],label=linsig[i]) plt.legend() plt.xlabel(&#39;g&#39;) plt.ylabel(&#39;Entropy&#39;) plt.show() . . Possiamo notare come per valori della varianza maggiori di 0.1 il picco, oltre ad abbassarsi notevolmente, sembra spostarsi progressivamente pi√π a sinistra. . Per approfondire meglio questo effetto andremo a fare gli stessi passaggi fatti finora, ma considerando le fluttuazioni random sul campo esterno $g$. . Campi esterni a valori random . Di seguito √® riportato il grafico, ed il codice espandibile, di un modello di Ising 1D in cui i valori di $g_i$ non sono uguali per tutta la catena, ma vengono estratti da una distribuzione normale con media $g_m$ variabile e varianza, in questo caso, uguale a 0.4. . #collapse m=10 NIter=200 rep=20 rep+=1 gmax=2 ling=np.linspace(0,gmax,rep) Evec=np.zeros(rep) Entropy=np.zeros(rep) ggg=0 # inizialize local ops I=np.eye(2,2) Sz=np.array([[1, 0],[0,-1]]) Sx=np.array([[0, 1],[1,0]]) # initial blocks for gm in ling: Ent=0 BlockSz = Sz BlockSx = Sx BlockI = I BlockH = np.random.default_rng().normal(gm, .4)*Sx Energy = 0 for l in range(NIter): SystSize = 2*l + 4 g=np.random.default_rng().normal(gm, .4) # Get the 2m-dimensional operators for the block + site BlockH = np.kron(BlockH, I) + np.kron(BlockI, g*Sx) - np.kron(BlockSz, Sz) BlockSz = np.kron(BlockI, Sz) BlockSx = np.kron(BlockI, Sx) BlockI = np.kron(BlockI, I) # HAMILTONIAN MATRIX for superblock H_super = np.kron(BlockH, BlockI) + np.kron(BlockI, BlockH) - np.kron(BlockSz, BlockSz) H_super = 0.5 * (H_super + H_super.T); # ensure H is symmetric # Diagonalizing the Hamiltonian LastEnergy = Energy Energy= ssl.eigsh(H_super,1,which=&#39;SA&#39;)[0] #[0] Psi = ssl.eigsh(H_super,1,which=&#39;SA&#39;)[1].T #[0] EnergyPerBond = (Energy - LastEnergy) / 2 Ener2 = Energy / SystSize # Sigma = Psi&#39; *kron(BlockSz,BlockSz) * Psi; % n.n. ZZ correlation function # Form the reduced density matrix nr=Psi.size Dim = int(np.sqrt(nr)) PsiMatrix = np.reshape(Psi,(Dim,Dim)) Rho = PsiMatrix @ PsiMatrix.T # Diagonalize the density matrix D,V = np.linalg.eigh(Rho) D=D[::-1] # descending Index=np.arange(Dim) Index=Index[::-1] V=V[:,Index] # Construct the truncation operator NKeep = min(D.size, m) Omatr = V[:,:NKeep] TruncationError = 1 - sum(D[:NKeep]) # Transform the block operators into the truncated basis BlockH = Omatr.T @ BlockH @ Omatr BlockSz = Omatr.T @ BlockSz @ Omatr BlockSx = Omatr.T @ BlockSx @ Omatr BlockI = Omatr.T @ BlockI @ Omatr #print(SystSize, Energy, EnergyPerBond, Ener2, TruncationError) Ent=-sum(D[:NKeep]*np.log(D[:NKeep])) #Evec[ggg]=Energy Entropy[ggg]=Ent ggg+=1 plt.plot(ling,Entropy) plt.show() . . Oltre a presentare le stesse caratteristiche di prima presenta uno spostamento del picco verso destra, in maniera opposta rispetto a prima. . Fluttuazioni mediate . Di seguito sono state calcolate varie realizzazioni di catene di Ising con campi esterni a valori random, per poi calcolarne la media, in maniera da essere sicuri che questo effetto non sia solo statistico. . #collapse m=8 NIter=200 rep=30 rep+=1 gmax=2 ling=np.linspace(0,gmax,rep) nrip=6 #ling=ling[int(30*rep/100):] Evec=np.zeros((rep,nrip)) Entropy=np.zeros((rep,nrip)) ggg=0 # inizialize local ops I=np.eye(2,2) Sz=np.array([[1, 0],[0,-1]]) Sx=np.array([[0, 1],[1,0]]) # initial blocks for gm in ling: for rip in range(nrip): BlockSz = Sz BlockSx = Sx BlockI = I BlockH = np.random.default_rng().normal(gm, .5)*Sx Energy = 0 for l in range(NIter): SystSize = 2*l + 4 g=np.random.default_rng().normal(gm, .5) # Get the 2m-dimensional operators for the block + site BlockH = np.kron(BlockH, I) + np.kron(BlockI, g*Sx) - np.kron(BlockSz, Sz) BlockSz = np.kron(BlockI, Sz) BlockSx = np.kron(BlockI, Sx) BlockI = np.kron(BlockI, I) # HAMILTONIAN MATRIX for superblock H_super = np.kron(BlockH, BlockI) + np.kron(BlockI, BlockH) - np.kron(BlockSz, BlockSz) H_super = 0.5 * (H_super + H_super.T); # ensure H is symmetric # Diagonalizing the Hamiltonian LastEnergy = Energy Energy= ssl.eigsh(H_super,1,which=&#39;SA&#39;)[0] #[0] Psi = ssl.eigsh(H_super,1,which=&#39;SA&#39;)[1].T #[0] EnergyPerBond = (Energy - LastEnergy) / 2 Ener2 = Energy / SystSize # Sigma = Psi&#39; *kron(BlockSz,BlockSz) * Psi; % n.n. ZZ correlation function # Form the reduced density matrix nr=Psi.size Dim = int(np.sqrt(nr)) PsiMatrix = np.reshape(Psi,(Dim,Dim)) Rho = PsiMatrix @ PsiMatrix.T # Diagonalize the density matrix D,V = np.linalg.eigh(Rho) D=D[::-1] # descending Index=np.arange(Dim) Index=Index[::-1] V=V[:,Index] # Construct the truncation operator NKeep = min(D.size, m) Omatr = V[:,:NKeep] TruncationError = 1 - sum(D[:NKeep]) # Transform the block operators into the truncated basis BlockH = Omatr.T @ BlockH @ Omatr BlockSz = Omatr.T @ BlockSz @ Omatr BlockSx = Omatr.T @ BlockSx @ Omatr BlockI = Omatr.T @ BlockI @ Omatr #print(SystSize, Energy, EnergyPerBond, Ener2, TruncationError) Ent=-sum(D[:NKeep]*np.log(D[:NKeep])) Evec[ggg,rip]=Energy Entropy[ggg,rip]=Ent ggg+=1 #Spectrum=ssl.eigsh(H_super)[0] plt.plot(ling[1:],Entropy[1:]) plt.plot(ling[1:],np.sum(Entropy[1:],axis=1)/nrip,color=&#39;k&#39;, linewidth=2.0) plt.show() . . Anche in questo caso si pu√≤ osservare come lo spostamento verso destra non dipenda dalla statistica. . Comportamento per diverse varianze . Guardiamo ora il comportamento delle medie dei grafici dell&#39;entropia per alcuni valori di varianze diverse. . #collapse m=8 NIter=200 rep=30 rep+=1 gmax=2 Nmedie=5 ling=np.linspace(0.5,gmax,rep) linsig=np.linspace(0.1,1,Nmedie) nrip=8 #ling=ling[int(30*rep/100):] Evec=np.zeros((rep,nrip)) Entropy=np.zeros((rep,nrip)) MEnt=np.zeros((Nmedie,rep-1)) ggg=0 # inizialize local ops I=np.eye(2,2) Sz=np.array([[1, 0],[0,-1]]) Sx=np.array([[0, 1],[1,0]]) # initial blocks sss=0 for sig in linsig: ggg=0 for gm in ling: for rip in range(nrip): BlockSz = Sz BlockSx = Sx BlockI = I #BlockH = gm*Sx BlockH = np.random.default_rng().normal(gm, sig)*Sx Energy = 0 for l in range(NIter): SystSize = 2*l + 4 g=np.random.default_rng().normal(gm, sig) # Get the 2m-dimensional operators for the block + site BlockH = np.kron(BlockH, I) + np.kron(BlockI, g*Sx) - np.kron(BlockSz, Sz) BlockSz = np.kron(BlockI, Sz) BlockSx = np.kron(BlockI, Sx) BlockI = np.kron(BlockI, I) # HAMILTONIAN MATRIX for superblock H_super = np.kron(BlockH, BlockI) + np.kron(BlockI, BlockH) - np.kron(BlockSz, BlockSz) H_super = 0.5 * (H_super + H_super.T); # ensure H is symmetric # Diagonalizing the Hamiltonian LastEnergy = Energy Energy= ssl.eigsh(H_super,1,which=&#39;SA&#39;)[0] #[0] Psi = ssl.eigsh(H_super,1,which=&#39;SA&#39;)[1].T #[0] EnergyPerBond = (Energy - LastEnergy) / 2 Ener2 = Energy / SystSize # Sigma = Psi&#39; *kron(BlockSz,BlockSz) * Psi; % n.n. ZZ correlation function # Form the reduced density matrix nr=Psi.size Dim = int(np.sqrt(nr)) PsiMatrix = np.reshape(Psi,(Dim,Dim)) Rho = PsiMatrix @ PsiMatrix.T # Diagonalize the density matrix D,V = np.linalg.eigh(Rho) D=D[::-1] # descending Index=np.arange(Dim) Index=Index[::-1] V=V[:,Index] # Construct the truncation operator NKeep = min(D.size, m) Omatr = V[:,:NKeep] TruncationError = 1 - sum(D[:NKeep]) # Transform the block operators into the truncated basis BlockH = Omatr.T @ BlockH @ Omatr BlockSz = Omatr.T @ BlockSz @ Omatr BlockSx = Omatr.T @ BlockSx @ Omatr BlockI = Omatr.T @ BlockI @ Omatr #print(SystSize, Energy, EnergyPerBond, Ener2, TruncationError) Ent=-sum(D[:NKeep]*np.log(D[:NKeep])) #Evec[ggg,rip]=Energy Entropy[ggg,rip]=Ent ggg+=1 MEnt[sss]=np.sum(Entropy[1:],axis=1)/nrip sss+=1 #Spectrum=ssl.eigsh(H_super)[0] plt.plot(ling[1:],MEnt.T) #plt.legend() plt.show() . . Anche in questo caso si pu√≤ apprezzare un graduale allontanamento del picco verso destra, nel senso opposto che nel caso delle interazioni a primi vicini con valori random. . Una possibile spiegazione . Ricordandoci che il punto critico del modello di Ising &quot;normale&quot; si trova per valori di $g$ e $J$ tali che $g/J=1$ possiamo notare che i due parametri competono in maniera reciproca al punto di transizione, quindi √® legittimo pensare di aver &quot;sbagliato&quot; ad imporre un tipo di rumore gaussiano ad entrambi i parametri, mentre in uno dei due avremmo dovuto imporre un rumore preso dall&#39;inverso di una distribuzione gaussiana. . Per testare questa ipotesi andiamo a cambiare il parametro $J$ nel codice in $1/J$ che rimane comunque con la stessa media poich√® essa √® sempre stata fissata ad 1. . #collapse m=9 NIter=200 rep=100 rep+=1 gmax=1.5 ling=np.linspace(0.5,gmax,rep) nrip=20 Evec=np.zeros((rep,nrip)) Entropy=np.zeros((rep,nrip)) ggg=0 # inizialize local ops I=np.eye(2,2) Sz=np.array([[1, 0],[0,-1]]) Sx=np.array([[0, 1],[1,0]]) # initial blocks for gm in ling: for rip in range(nrip): BlockSz = Sz BlockSx = Sx BlockI = I BlockH = gm*Sx Energy = 0 for l in range(NIter): SystSize = 2*l + 4 g=gm j1=np.random.default_rng().normal(1, .4) # Get the 2m-dimensional operators for the block + site BlockH = np.kron(BlockH, I) + np.kron(BlockI, g*Sx) - np.kron(BlockSz, Sz)/j1 BlockSz = np.kron(BlockI, Sz) BlockSx = np.kron(BlockI, Sx) BlockI = np.kron(BlockI, I) # HAMILTONIAN MATRIX for superblock j2=np.random.default_rng().normal(1, .4) H_super = np.kron(BlockH, BlockI) + np.kron(BlockI, BlockH) - np.kron(BlockSz, BlockSz)/j2 H_super = 0.5 * (H_super + H_super.T); # ensure H is symmetric # Diagonalizing the Hamiltonian LastEnergy = Energy Energy= ssl.eigsh(H_super,1,which=&#39;SA&#39;)[0] #[0] Psi = ssl.eigsh(H_super,1,which=&#39;SA&#39;)[1].T #[0] EnergyPerBond = (Energy - LastEnergy) / 2 Ener2 = Energy / SystSize # Sigma = Psi&#39; *kron(BlockSz,BlockSz) * Psi; % n.n. ZZ correlation function # Form the reduced density matrix nr=Psi.size Dim = int(np.sqrt(nr)) PsiMatrix = np.reshape(Psi,(Dim,Dim)) Rho = PsiMatrix @ PsiMatrix.T # Diagonalize the density matrix D,V = np.linalg.eigh(Rho) D=D[::-1] # descending Index=np.arange(Dim) Index=Index[::-1] V=V[:,Index] # Construct the truncation operator NKeep = min(D.size, m) Omatr = V[:,:NKeep] TruncationError = 1 - sum(D[:NKeep]) # Transform the block operators into the truncated basis BlockH = Omatr.T @ BlockH @ Omatr BlockSz = Omatr.T @ BlockSz @ Omatr BlockSx = Omatr.T @ BlockSx @ Omatr BlockI = Omatr.T @ BlockI @ Omatr Ent=-sum(D[:NKeep]*np.log(D[:NKeep])) Evec[ggg,rip]=Energy Entropy[ggg,rip]=Ent ggg+=1 EntMed1=np.sum(Entropy[1:],axis=1)/nrip plt.plot(ling[1:],Entropy[1:]) plt.plot(ling[1:],EntMed1,color=&#39;k&#39;, linewidth=2.0) plt.show() . . A parte la grande fluttuazione dei singoli grafici, possiamo notare come in media effettivamente il picco si sia spostato verso valori di $g$ maggiori, contrariamente a prima e in maniera concorde con il caso del rumore su $g$. . Per controllare quest&#39;ultima affermazione andremo a fare lo stesso calcolo con gli stessi valori dell&#39;algoritmo e con la stessa varianza ma su $g$ come prima. . #collapse m=9 NIter=200 rep=100 rep+=1 gmax=1.5 ling=np.linspace(0.5,gmax,rep) nrip=20 #ling=ling[int(30*rep/100):] Evec=np.zeros((rep,nrip)) Entropy=np.zeros((rep,nrip)) ggg=0 # inizialize local ops I=np.eye(2,2) Sz=np.array([[1, 0],[0,-1]]) Sx=np.array([[0, 1],[1,0]]) # initial blocks for gm in ling: for rip in range(nrip): BlockSz = Sz BlockSx = Sx BlockI = I BlockH = np.random.default_rng().normal(gm, .4)*Sx Energy = 0 for l in range(NIter): SystSize = 2*l + 4 g=np.random.default_rng().normal(gm, .4) # Get the 2m-dimensional operators for the block + site BlockH = np.kron(BlockH, I) + np.kron(BlockI, g*Sx) - np.kron(BlockSz, Sz) BlockSz = np.kron(BlockI, Sz) BlockSx = np.kron(BlockI, Sx) BlockI = np.kron(BlockI, I) # HAMILTONIAN MATRIX for superblock H_super = np.kron(BlockH, BlockI) + np.kron(BlockI, BlockH) - np.kron(BlockSz, BlockSz) H_super = 0.5 * (H_super + H_super.T); # ensure H is symmetric # Diagonalizing the Hamiltonian LastEnergy = Energy Energy= ssl.eigsh(H_super,1,which=&#39;SA&#39;)[0] #[0] Psi = ssl.eigsh(H_super,1,which=&#39;SA&#39;)[1].T #[0] EnergyPerBond = (Energy - LastEnergy) / 2 Ener2 = Energy / SystSize # Sigma = Psi&#39; *kron(BlockSz,BlockSz) * Psi; % n.n. ZZ correlation function # Form the reduced density matrix nr=Psi.size Dim = int(np.sqrt(nr)) PsiMatrix = np.reshape(Psi,(Dim,Dim)) Rho = PsiMatrix @ PsiMatrix.T # Diagonalize the density matrix D,V = np.linalg.eigh(Rho) D=D[::-1] # descending Index=np.arange(Dim) Index=Index[::-1] V=V[:,Index] # Construct the truncation operator NKeep = min(D.size, m) Omatr = V[:,:NKeep] TruncationError = 1 - sum(D[:NKeep]) # Transform the block operators into the truncated basis BlockH = Omatr.T @ BlockH @ Omatr BlockSz = Omatr.T @ BlockSz @ Omatr BlockSx = Omatr.T @ BlockSx @ Omatr BlockI = Omatr.T @ BlockI @ Omatr #print(SystSize, Energy, EnergyPerBond, Ener2, TruncationError) Ent=-sum(D[:NKeep]*np.log(D[:NKeep])) Evec[ggg,rip]=Energy Entropy[ggg,rip]=Ent ggg+=1 EntMed2=np.sum(Entropy[1:],axis=1)/nrip plt.plot(ling[1:],Entropy[1:]) plt.plot(ling[1:],EntMed2,color=&#39;k&#39;, linewidth=2.0) plt.show() . . Anche in questo caso osserviamo lo stesso spostamento del picco verso destra anche se il valore di $g$ relativo al picco non √® lo stesso che nel caso precedente. Questo fatto potrebbe essere dovuto o alla statistica o, pi√π probabilmente, al fatto che per ritrovare la stessa distribuzione la varianza su $g$ non deve essere la stessa di quella su $J$ che poi deve essere invertita, ma comunque il comportamento generale sembra essere pi√π o meno quello, come dimostrato dalla differenza delle due medie precedenti che mostrano comunque scostamenti non eccessivi dallo zero. . #collapse plt.plot(ling[1:],EntMed1-EntMed2) plt.show() . .",
            "url": "https://edoarder.github.io/Metodi_Numerici/2020/06/06/DMRG-Random_Ising-8.html",
            "relUrl": "/2020/06/06/DMRG-Random_Ising-8.html",
            "date": " ‚Ä¢ Jun 6, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Io sono Edoardo Maggioni, studente del secondo anno di Fisica Teorica presso l‚ÄôUniversit√† di Pisa. . Sono nato a Siena, dove sono cresciuto e dove ho frequentato il corso di laurea triennale in Fisica e Tecnologie Avanzate, laureandomi con lode. . Al di fuori del mondo della fisica ho coltivato svariati hobby, mi piace appassionarmi per certi periodi ad argomenti particolari di mio interesse che vanno dall‚Äôinformatica al Judo, dall‚ÄôUltimate Frisbee all‚Äôarte. Il mio interesse principale √® la musica, sia ascoltarla che suonarla: riesco ad apprezzare un gran numero di generi musicali, specialmente contemporanei. Suono tastiera e chitarra, ho studiato armonia e qualcosa di composizione. Conosco le basi della produzione musicale analogica e digitale ed ogni tanto faccio qualche brano. Ho infine seguito e conseguito l‚Äôesame di Fisica Musicale per il quale ho sviluppato interamente un sintetizzatore con Matlab. . Nella mia vita ho viaggiato tanto, specialmente in Europa, ma punto a viaggiare ancora di pi√π in futuro. . Considero l‚Äôoriginalit√† uno dei tratti essenziali della vita in generale. .",
          "url": "https://edoarder.github.io/Metodi_Numerici/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://edoarder.github.io/Metodi_Numerici/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}